{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary\n!pip install torchgeometry","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:17.787543Z","iopub.execute_input":"2023-11-15T03:27:17.787926Z","iopub.status.idle":"2023-11-15T03:27:43.165038Z","shell.execute_reply.started":"2023-11-15T03:27:17.787892Z","shell.execute_reply":"2023-11-15T03:27:43.163832Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\nCollecting torchgeometry\n  Downloading torchgeometry-0.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\nInstalling collected packages: torchgeometry\nSuccessfully installed torchgeometry-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchsummary import summary\nfrom torchgeometry.losses import one_hot\nimport os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport cv2\nimport time\nimport imageio\nimport matplotlib.pyplot as plt\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch import Tensor\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.transforms import Resize, PILToTensor, ToPILImage, Compose, InterpolationMode\nfrom collections import OrderedDict\nimport wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-15T03:27:43.167434Z","iopub.execute_input":"2023-11-15T03:27:43.167801Z","iopub.status.idle":"2023-11-15T03:27:46.162327Z","shell.execute_reply.started":"2023-11-15T03:27:43.167771Z","shell.execute_reply":"2023-11-15T03:27:46.161482Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.compat.v1 import InteractiveSession\n\n# tf.keras.backend.clear_session()\n# config = tf.compat.v1.ConfigProto()\n# config.gpu_options.allow_growth = True\n# session = InteractiveSession(config=config)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:46.163688Z","iopub.execute_input":"2023-11-15T03:27:46.163968Z","iopub.status.idle":"2023-11-15T03:27:46.167796Z","shell.execute_reply.started":"2023-11-15T03:27:46.163943Z","shell.execute_reply":"2023-11-15T03:27:46.166717Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:46.170672Z","iopub.execute_input":"2023-11-15T03:27:46.171301Z","iopub.status.idle":"2023-11-15T03:27:47.170950Z","shell.execute_reply.started":"2023-11-15T03:27:46.171268Z","shell.execute_reply":"2023-11-15T03:27:47.169712Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"GPU 0: Tesla T4 (UUID: GPU-d8732d44-098e-871a-486d-bf88b7488aff)\nGPU 1: Tesla T4 (UUID: GPU-cbe85986-0624-f845-a534-e66f9493bc52)\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.172355Z","iopub.execute_input":"2023-11-15T03:27:47.172697Z","iopub.status.idle":"2023-11-15T03:27:47.256886Z","shell.execute_reply.started":"2023-11-15T03:27:47.172647Z","shell.execute_reply":"2023-11-15T03:27:47.255806Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"# Number of class in the data set (3: neoplastic, non neoplastic, background)\nnum_classes = 3\n\n# Number of epoch\nepochs = 22\n\n# Hyperparameters for training \nlearning_rate = 2e-04\nbatch_size = 4\ndisplay_step = 50\n\n# Model path\ncheckpoint_path = '/kaggle/working/unet_model.pth'\npretrained_path = \"/kaggle/input/unet-checkpoint/unet_model.pth\"\n# Initialize lists to keep track of loss and accuracy\nloss_epoch_array = []\ntrain_accuracy = []\ntest_accuracy = []\nvalid_accuracy = []","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.258157Z","iopub.execute_input":"2023-11-15T03:27:47.258567Z","iopub.status.idle":"2023-11-15T03:27:47.265384Z","shell.execute_reply.started":"2023-11-15T03:27:47.258539Z","shell.execute_reply":"2023-11-15T03:27:47.264596Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"transform = Compose([Resize((800, 1120), interpolation=InterpolationMode.BILINEAR),\n                     PILToTensor()])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.266425Z","iopub.execute_input":"2023-11-15T03:27:47.266701Z","iopub.status.idle":"2023-11-15T03:27:47.274395Z","shell.execute_reply.started":"2023-11-15T03:27:47.266656Z","shell.execute_reply":"2023-11-15T03:27:47.273580Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class UNetDataClass(Dataset):\n    def __init__(self, images_path, masks_path, transform):\n        super(UNetDataClass, self).__init__()\n        \n        images_list = os.listdir(images_path)\n        masks_list = os.listdir(masks_path)\n        \n        images_list = [images_path + image_name for image_name in images_list]\n        masks_list = [masks_path + mask_name for mask_name in masks_list]\n        \n        self.images_list = images_list\n        self.masks_list = masks_list\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img_path = self.images_list[index]\n        mask_path = self.masks_list[index]\n        \n        # Open image and mask\n        data = Image.open(img_path)\n        label = Image.open(mask_path)\n        \n        # Normalize\n        data = self.transform(data) / 255\n        label = self.transform(label) / 255\n        \n        label = torch.where(label>0.65, 1.0, 0.0)\n        \n        label[2, :, :] = 0.0001\n        label = torch.argmax(label, 0).type(torch.int64)\n        \n        return data, label\n    \n    def __len__(self):\n        return len(self.images_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.275589Z","iopub.execute_input":"2023-11-15T03:27:47.276356Z","iopub.status.idle":"2023-11-15T03:27:47.286634Z","shell.execute_reply.started":"2023-11-15T03:27:47.276332Z","shell.execute_reply":"2023-11-15T03:27:47.285857Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\nmasks_path =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\"","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.287811Z","iopub.execute_input":"2023-11-15T03:27:47.288188Z","iopub.status.idle":"2023-11-15T03:27:47.300161Z","shell.execute_reply.started":"2023-11-15T03:27:47.288157Z","shell.execute_reply":"2023-11-15T03:27:47.299191Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"unet_dataset = UNetDataClass(images_path, masks_path, transform)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.303302Z","iopub.execute_input":"2023-11-15T03:27:47.303677Z","iopub.status.idle":"2023-11-15T03:27:47.376898Z","shell.execute_reply.started":"2023-11-15T03:27:47.303649Z","shell.execute_reply":"2023-11-15T03:27:47.376204Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\nvalid_size = 0.2","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.377924Z","iopub.execute_input":"2023-11-15T03:27:47.378182Z","iopub.status.idle":"2023-11-15T03:27:47.382112Z","shell.execute_reply.started":"2023-11-15T03:27:47.378159Z","shell.execute_reply":"2023-11-15T03:27:47.381144Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_set, valid_set = random_split(unet_dataset, \n                                    [int(train_size * len(unet_dataset)) , \n                                     int(valid_size * len(unet_dataset))])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.383371Z","iopub.execute_input":"2023-11-15T03:27:47.383944Z","iopub.status.idle":"2023-11-15T03:27:47.411246Z","shell.execute_reply.started":"2023-11-15T03:27:47.383919Z","shell.execute_reply":"2023-11-15T03:27:47.410356Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nvalid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.412610Z","iopub.execute_input":"2023-11-15T03:27:47.413201Z","iopub.status.idle":"2023-11-15T03:27:47.419476Z","shell.execute_reply.started":"2023-11-15T03:27:47.413169Z","shell.execute_reply":"2023-11-15T03:27:47.418717Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from albumentations import (\n    Compose,\n    RandomRotate90,\n    Flip,\n    Transpose,\n    ElasticTransform,\n    GridDistortion,\n    OpticalDistortion,\n    RandomBrightnessContrast,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.420692Z","iopub.execute_input":"2023-11-15T03:27:47.421023Z","iopub.status.idle":"2023-11-15T03:27:47.429013Z","shell.execute_reply.started":"2023-11-15T03:27:47.420993Z","shell.execute_reply":"2023-11-15T03:27:47.428221Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"augmentation = Compose([\n    RandomRotate90(),\n    Flip(),\n    Transpose(),\n    ElasticTransform(),\n    GridDistortion(),\n    OpticalDistortion(),\n    RandomBrightnessContrast(),\n])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.430048Z","iopub.execute_input":"2023-11-15T03:27:47.430414Z","iopub.status.idle":"2023-11-15T03:27:47.438771Z","shell.execute_reply.started":"2023-11-15T03:27:47.430375Z","shell.execute_reply":"2023-11-15T03:27:47.437823Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class SegmentationDataset:\n    def __init__(self, images_path, masks_path, first_transform=None, second_transform = None):\n        super(SegmentationDataset, self).__init__()\n        \n        images_list = os.listdir(images_path)\n        masks_list = os.listdir(masks_path)\n        \n        images_list = [images_path + image_name for image_name in images_list]\n        masks_list = [masks_path + mask_name for mask_name in masks_list]\n        \n        self.images_list = images_list\n        self.masks_list = masks_list\n        self.first_transform = first_transform\n        self.second_transform = second_transform\n        \n    def __getitem__(self, index):\n        img_path = self.images_list[index]\n        mask_path = self.masks_list[index]\n        \n        # Open image and mask\n        data = Image.open(img_path)\n        label = Image.open(mask_path)\n        \n        # Normalize\n        data = self.first_transform(data) / 255\n        label = self.first_transform(label) / 255\n\n        if self.second_transform:\n            augmented = self.second_transform(data = data, label = label)\n            data = augmented(data)\n            label = augmented(label)\n        \n        label = torch.where(label>0.65, 1.0, 0.0)\n        \n        label[2, :, :] = 0.0001\n        label = torch.argmax(label, 0).type(torch.int64)\n        \n        return data, label\n    \n    def __len__(self):\n        return len(self.images_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:27:47.439788Z","iopub.execute_input":"2023-11-15T03:27:47.440042Z","iopub.status.idle":"2023-11-15T03:27:47.452884Z","shell.execute_reply.started":"2023-11-15T03:27:47.440020Z","shell.execute_reply":"2023-11-15T03:27:47.452071Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"transform = Compose([Resize((800, 1120), interpolation=InterpolationMode.BILINEAR),\n                     PILToTensor()])\naugment_set = SegmentationDataset(images_path, masks_path, transform, augmentation)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:28:05.305511Z","iopub.execute_input":"2023-11-15T03:28:05.306428Z","iopub.status.idle":"2023-11-15T03:28:05.313209Z","shell.execute_reply.started":"2023-11-15T03:28:05.306393Z","shell.execute_reply":"2023-11-15T03:28:05.312274Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\nvalid_size = 0.2\ntrain_set, valid_set = random_split(unet_dataset, \n                                    [int(train_size * len(unet_dataset)) , \n                                     int(valid_size * len(unet_dataset))])\ntrain_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nvalid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:25.530521Z","iopub.execute_input":"2023-11-15T03:30:25.531477Z","iopub.status.idle":"2023-11-15T03:30:25.537325Z","shell.execute_reply.started":"2023-11-15T03:30:25.531441Z","shell.execute_reply":"2023-11-15T03:30:25.536352Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"**Residual Block**","metadata":{}},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ResidualBlock, self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.bn3 = nn.BatchNorm2d(out_channels)\n        \n        self.dropout = nn.Dropout(p=0.3)\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        \n        out = self.dropout(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        residual = self.conv1(residual)\n        residual = self.bn3(residual)\n\n        out += residual  \n        out = self.relu(out)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:36.701551Z","iopub.execute_input":"2023-11-15T03:30:36.701930Z","iopub.status.idle":"2023-11-15T03:30:36.711190Z","shell.execute_reply.started":"2023-11-15T03:30:36.701898Z","shell.execute_reply":"2023-11-15T03:30:36.710231Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"**Encoder Block**","metadata":{}},{"cell_type":"code","source":"class encoder_block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(encoder_block, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.3)\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        next_layer = self.max_pool(x)\n        skip_layer = x\n        \n        return next_layer, skip_layer","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:37.350537Z","iopub.execute_input":"2023-11-15T03:30:37.350915Z","iopub.status.idle":"2023-11-15T03:30:37.359901Z","shell.execute_reply.started":"2023-11-15T03:30:37.350879Z","shell.execute_reply":"2023-11-15T03:30:37.358828Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class res_encoder_block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(res_encoder_block, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.bn3 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.3)\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n    def forward(self, x):\n        residual = x\n        \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        \n        residual = self.conv1(residual)\n        residual = self.bn3(residual)\n        \n        \n        x += residual  \n        x = self.relu(x)\n        \n        next_layer = self.max_pool(x)\n        skip_layer = x\n        \n        return next_layer, skip_layer","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:38.021195Z","iopub.execute_input":"2023-11-15T03:30:38.021577Z","iopub.status.idle":"2023-11-15T03:30:38.033601Z","shell.execute_reply.started":"2023-11-15T03:30:38.021544Z","shell.execute_reply":"2023-11-15T03:30:38.032542Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"**Decoder block**","metadata":{}},{"cell_type":"code","source":"class decoder_block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(decoder_block, self).__init__()\n        \n        self.transpose_conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n        \n        self.conv1 = nn.Conv2d(2 * out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU() \n        self.dropout = nn.Dropout(p=0.3)\n    \n    def forward(self, x, skip_layer):\n        x = self.transpose_conv(x)\n        x = torch.cat([x, skip_layer], axis=1)\n        \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:38.974164Z","iopub.execute_input":"2023-11-15T03:30:38.974528Z","iopub.status.idle":"2023-11-15T03:30:38.984015Z","shell.execute_reply.started":"2023-11-15T03:30:38.974498Z","shell.execute_reply":"2023-11-15T03:30:38.983087Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class res_decoder_block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(res_decoder_block, self).__init__()\n        \n        self.transpose_conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n        \n        self.conv1 = nn.Conv2d(2 * out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.bn3 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU() \n        self.dropout = nn.Dropout(p=0.3)\n    \n    def forward(self, x, skip_layer):\n        x = self.transpose_conv(x)\n        x = torch.cat([x, skip_layer], axis=1)\n        \n        residual = x\n        \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        \n        residual = self.conv1(residual)\n        residual = self.bn3(residual)\n        \n        x += residual\n        x = self.relu(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:39.429924Z","iopub.execute_input":"2023-11-15T03:30:39.430681Z","iopub.status.idle":"2023-11-15T03:30:39.440294Z","shell.execute_reply.started":"2023-11-15T03:30:39.430635Z","shell.execute_reply":"2023-11-15T03:30:39.439230Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"**Bottle neck**","metadata":{}},{"cell_type":"code","source":"class bottleneck_block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(bottleneck_block, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.3)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:40.399155Z","iopub.execute_input":"2023-11-15T03:30:40.400045Z","iopub.status.idle":"2023-11-15T03:30:40.407849Z","shell.execute_reply.started":"2023-11-15T03:30:40.400009Z","shell.execute_reply":"2023-11-15T03:30:40.406942Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"**Unet model**","metadata":{}},{"cell_type":"code","source":"# UNet model\nclass UNet(nn.Module):\n    def __init__(self, n_class=3):\n        super(UNet, self).__init__()\n        # Encoder blocks\n        self.enc1 = encoder_block(3, 64)\n        self.enc2 = encoder_block(64, 128)\n        self.enc3 = res_encoder_block(128, 256)\n        self.enc4 = encoder_block(256, 512)\n        \n        # Bottleneck block\n        self.bottleneck = ResidualBlock(512, 1024)\n        \n        # Decoder blocks\n        self.dec1 = decoder_block(1024, 512)\n        self.dec2 = res_decoder_block(512, 256)\n        self.dec3 = decoder_block(256, 128)\n        self.dec4 = decoder_block(128, 64)\n        \n        # 1x1 convolution\n        self.out = nn.Conv2d(64, n_class, kernel_size=1, padding='same')\n        \n    def forward(self, image):\n        n1, s1 = self.enc1(image)\n        n2, s2 = self.enc2(n1)\n        n3, s3 = self.enc3(n2)\n        n4, s4 = self.enc4(n3)\n        \n        n5 = self.bottleneck(n4)\n        \n        n6 = self.dec1(n5, s4)\n        n7 = self.dec2(n6, s3)\n        n8 = self.dec3(n7, s2)\n        n9 = self.dec4(n8, s1)\n        \n        output = self.out(n9)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:41.253023Z","iopub.execute_input":"2023-11-15T03:30:41.253690Z","iopub.status.idle":"2023-11-15T03:30:41.263237Z","shell.execute_reply.started":"2023-11-15T03:30:41.253649Z","shell.execute_reply":"2023-11-15T03:30:41.262165Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Loss function","metadata":{}},{"cell_type":"code","source":"class CEDiceLoss(nn.Module):\n    def __init__(self, weights) -> None:\n        super(CEDiceLoss, self).__init__()\n        self.eps: float = 1e-6\n        self.weights: torch.Tensor = weights\n\n    def forward(\n            self,\n            input: torch.Tensor,\n            target: torch.Tensor) -> torch.Tensor:\n        if not torch.is_tensor(input):\n            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n                            .format(type(input)))\n        if not len(input.shape) == 4:\n            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n                             .format(input.shape))\n        if not input.shape[-2:] == target.shape[-2:]:\n            raise ValueError(\"input and target shapes must be the same. Got: {}\"\n                             .format(input.shape, input.shape))\n        if not input.device == target.device:\n            raise ValueError(\n                \"input and target must be in the same device. Got: {}\" .format(\n                    input.device, target.device))\n        if not self.weights.shape[1] == input.shape[1]:\n            raise ValueError(\"The number of weights must equal the number of classes\")\n        if not torch.sum(self.weights).item() == 1:\n            raise ValueError(\"The sum of all weights must equal 1\")\n            \n        # cross entropy loss\n        celoss = nn.CrossEntropyLoss(self.weights)(input, target)\n        \n        # compute softmax over the classes axis\n        input_soft = F.softmax(input, dim=1)\n\n        # create the labels one hot tensor\n        target_one_hot = one_hot(target, num_classes=input.shape[1],\n                                 device=input.device, dtype=input.dtype)\n\n        # compute the actual dice score\n        dims = (2, 3)\n        intersection = torch.sum(input_soft * target_one_hot, dims)\n        cardinality = torch.sum(input_soft + target_one_hot, dims)\n\n        dice_score = 2. * intersection / (cardinality + self.eps)\n        \n        dice_score = torch.sum(dice_score * self.weights, dim=1)\n        \n        return torch.mean(1. - dice_score) + celoss\n#         return dice_score","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:42.479454Z","iopub.execute_input":"2023-11-15T03:30:42.480204Z","iopub.status.idle":"2023-11-15T03:30:42.492976Z","shell.execute_reply.started":"2023-11-15T03:30:42.480171Z","shell.execute_reply":"2023-11-15T03:30:42.491921Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"**Initialize weights**","metadata":{}},{"cell_type":"code","source":"def weights_init(model):\n    if isinstance(model, nn.Linear):\n        # Xavier Distribution\n        torch.nn.init.xavier_uniform_(model.weight)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:44.405963Z","iopub.execute_input":"2023-11-15T03:30:44.406799Z","iopub.status.idle":"2023-11-15T03:30:44.411284Z","shell.execute_reply.started":"2023-11-15T03:30:44.406768Z","shell.execute_reply":"2023-11-15T03:30:44.410376Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def save_model(model, optimizer, path):\n    checkpoint = {\n        \"model\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, path)\n\ndef load_model(model, optimizer, path):\n    checkpoint = torch.load(path)\n    model.load_state_dict(checkpoint[\"model\"])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    return model, optimizer","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:45.457169Z","iopub.execute_input":"2023-11-15T03:30:45.458077Z","iopub.status.idle":"2023-11-15T03:30:45.463847Z","shell.execute_reply.started":"2023-11-15T03:30:45.458044Z","shell.execute_reply":"2023-11-15T03:30:45.462858Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"# Train function for each epoch\ndef train(train_dataloader, valid_dataloader,learing_rate_scheduler, epoch, display_step):\n    print(f\"Start epoch #{epoch+1}, learning rate for this epoch: {learing_rate_scheduler.get_last_lr()}\")\n    start_time = time.time()\n    train_loss_epoch = 0\n    test_loss_epoch = 0\n    last_loss = 999999999\n    model.train()\n    for i, (data,targets) in enumerate(train_dataloader):\n        \n        # Load data into GPU\n        data, targets = data.to(device), targets.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(data)\n\n        # Backpropagation, compute gradients\n        loss = loss_function(outputs, targets.long())\n        loss.backward()\n\n        # Apply gradients\n        optimizer.step()\n        \n        # Save loss\n        train_loss_epoch += loss.item()\n        if (i+1) % display_step == 0:\n#             accuracy = float(test(test_loader))\n            print('Train Epoch: {} [{}/{} ({}%)]\\tLoss: {:.4f}'.format(\n                epoch + 1, (i+1) * len(data), len(train_dataloader.dataset), 100 * (i+1) * len(data) / len(train_dataloader.dataset), \n                loss.item()))\n                  \n    print(f\"Done epoch #{epoch+1}, time for this epoch: {time.time()-start_time}s\")\n    train_loss_epoch/= (i + 1)\n    \n    # Evaluate the validation set\n    model.eval()\n    with torch.no_grad():\n        for data, target in valid_dataloader:\n            data, target = data.to(device), target.to(device)\n            test_output = model(data)\n            test_loss = loss_function(test_output, target)\n            test_loss_epoch += test_loss.item()\n            \n    test_loss_epoch/= (i+1)\n    \n    return train_loss_epoch , test_loss_epoch","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:47.755985Z","iopub.execute_input":"2023-11-15T03:30:47.756597Z","iopub.status.idle":"2023-11-15T03:30:47.766436Z","shell.execute_reply.started":"2023-11-15T03:30:47.756565Z","shell.execute_reply":"2023-11-15T03:30:47.765619Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Test function\ndef test(dataloader):\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for i, (data, targets) in enumerate(dataloader):\n            data, targets = data.to(device), targets.to(device)\n            outputs = model(data)\n            _, pred = torch.max(outputs, 1)\n            test_loss += targets.size(0)\n            correct += torch.sum(pred == targets).item()\n    return 100.0 * correct / test_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:49.470325Z","iopub.execute_input":"2023-11-15T03:30:49.471185Z","iopub.status.idle":"2023-11-15T03:30:49.477585Z","shell.execute_reply.started":"2023-11-15T03:30:49.471150Z","shell.execute_reply":"2023-11-15T03:30:49.476578Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model = UNet()\n\ntry:\n    checkpoint = torch.load(pretrained_path)\n\n    new_state_dict = OrderedDict()\n    for k, v in checkpoint['model'].items():\n        name = k[7:] # remove `module.`\n        new_state_dict[name] = v\n    # load params\n    model.load_state_dict(new_state_dict)\n    model = nn.DataParallel(model)\n    model.to(device)\nexcept:\n    model.apply(weights_init)\n    model = nn.DataParallel(model)\n    model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:50.994081Z","iopub.execute_input":"2023-11-15T03:30:50.994887Z","iopub.status.idle":"2023-11-15T03:30:54.596971Z","shell.execute_reply.started":"2023-11-15T03:30:50.994857Z","shell.execute_reply":"2023-11-15T03:30:54.596158Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = torch.Tensor([[0.4, 0.55, 0.05]]).cuda()\nloss_function = CEDiceLoss(weights)\n\n# Define the optimizer (Adam optimizer)\noptimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\ntry: \n    optimizer.load_state_dict(checkpoint['optimizer'])\nexcept:\n    pass\n\n# Learning rate scheduler\nlearing_rate_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.6)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:54.598982Z","iopub.execute_input":"2023-11-15T03:30:54.599342Z","iopub.status.idle":"2023-11-15T03:30:54.607240Z","shell.execute_reply.started":"2023-11-15T03:30:54.599309Z","shell.execute_reply":"2023-11-15T03:30:54.606081Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"save_model(model, optimizer, checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:54.608601Z","iopub.execute_input":"2023-11-15T03:30:54.608960Z","iopub.status.idle":"2023-11-15T03:30:54.850929Z","shell.execute_reply.started":"2023-11-15T03:30:54.608934Z","shell.execute_reply":"2023-11-15T03:30:54.849897Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"wandb.login(\n    # set the wandb project where this run will be logged\n#     project= \"PolypSegment\", \n    key = \"90b1c43eb0f9a3084ba785bb7f308f0f948dfb31\",\n)\nwandb.init(\n    project = \"IWillKillYou\"\n)\n# Training loop\ntrain_loss_array = []\ntest_loss_array = []\nlast_loss = 9999999999999\nfor epoch in range(epochs):\n    train_loss_epoch = 0\n    test_loss_epoch = 0\n    (train_loss_epoch, test_loss_epoch) = train(train_dataloader, \n                                              valid_dataloader, \n                                              learing_rate_scheduler, epoch, display_step)\n    \n    if test_loss_epoch < last_loss:\n        save_model(model, optimizer, checkpoint_path)\n        last_loss = test_loss_epoch\n        \n    learing_rate_scheduler.step()\n    train_loss_array.append(train_loss_epoch)\n    test_loss_array.append(test_loss_epoch)\n    wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch})\n#     train_accuracy.append(test(train_loader))\n#     valid_accuracy.append(test(test_loader))\n#     print(\"Epoch {}: loss: {:.4f}, train accuracy: {:.4f}, valid accuracy:{:.4f}\".format(epoch + 1, \n#                                         train_loss_array[-1], train_accuracy[-1], valid_accuracy[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T03:30:54.852907Z","iopub.execute_input":"2023-11-15T03:30:54.853216Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhwnginsoict\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231115_033057-2cajnf4x</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hwnginsoict/IWillKillYou/runs/2cajnf4x' target=\"_blank\">sandy-sound-18</a></strong> to <a href='https://wandb.ai/hwnginsoict/IWillKillYou' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hwnginsoict/IWillKillYou' target=\"_blank\">https://wandb.ai/hwnginsoict/IWillKillYou</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hwnginsoict/IWillKillYou/runs/2cajnf4x' target=\"_blank\">https://wandb.ai/hwnginsoict/IWillKillYou/runs/2cajnf4x</a>"},"metadata":{}},{"name":"stdout","text":"Start epoch #1, learning rate for this epoch: [0.0002]\nTrain Epoch: 1 [200/800 (25.0%)]\tLoss: 1.6724\nTrain Epoch: 1 [400/800 (50.0%)]\tLoss: 1.8236\n","output_type":"stream"}]},{"cell_type":"code","source":"# torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.729730Z","iopub.status.idle":"2023-11-15T00:38:08.730215Z","shell.execute_reply.started":"2023-11-15T00:38:08.729977Z","shell.execute_reply":"2023-11-15T00:38:08.730000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save_model(model, optimizer, checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.731791Z","iopub.status.idle":"2023-11-15T00:38:08.732297Z","shell.execute_reply.started":"2023-11-15T00:38:08.732046Z","shell.execute_reply":"2023-11-15T00:38:08.732068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checkpoint = torch.load(pretrained_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.733724Z","iopub.status.idle":"2023-11-15T00:38:08.734196Z","shell.execute_reply.started":"2023-11-15T00:38:08.733963Z","shell.execute_reply":"2023-11-15T00:38:08.733985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checkpoint = torch.load(checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.735894Z","iopub.status.idle":"2023-11-15T00:38:08.736369Z","shell.execute_reply.started":"2023-11-15T00:38:08.736135Z","shell.execute_reply":"2023-11-15T00:38:08.736158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for m in self.children():\n#     m.cuda()\n#     x = m(x)\n#     m.cpu()\n#     torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.737809Z","iopub.status.idle":"2023-11-15T00:38:08.738314Z","shell.execute_reply.started":"2023-11-15T00:38:08.738074Z","shell.execute_reply":"2023-11-15T00:38:08.738098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot the learning cure","metadata":{}},{"cell_type":"code","source":"# load_model(model, checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.740820Z","iopub.status.idle":"2023-11-15T00:38:08.741279Z","shell.execute_reply.started":"2023-11-15T00:38:08.741056Z","shell.execute_reply":"2023-11-15T00:38:08.741078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.rcParams['figure.dpi'] = 90\n# plt.rcParams['figure.figsize'] = (6, 4)\n# epochs_array = range(epochs)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.742726Z","iopub.status.idle":"2023-11-15T00:38:08.743170Z","shell.execute_reply.started":"2023-11-15T00:38:08.742951Z","shell.execute_reply":"2023-11-15T00:38:08.742972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Plot Training and Test loss\n# plt.plot(epochs_array, train_loss_array, 'g', label='Training loss')\n# # plt.plot(epochs_array, test_loss_array, 'b', label='Test loss')\n# plt.title('Training and Test loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.744917Z","iopub.status.idle":"2023-11-15T00:38:08.745370Z","shell.execute_reply.started":"2023-11-15T00:38:08.745138Z","shell.execute_reply":"2023-11-15T00:38:08.745161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Infer**","metadata":{}},{"cell_type":"code","source":"# from torch.jit import load\n# model = UNet()\n# optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n\n# checkpoint = torch.load(pretrained_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.747042Z","iopub.status.idle":"2023-11-15T00:38:08.747469Z","shell.execute_reply.started":"2023-11-15T00:38:08.747247Z","shell.execute_reply":"2023-11-15T00:38:08.747267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer.load_state_dict(checkpoint['optimizer'])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.750051Z","iopub.status.idle":"2023-11-15T00:38:08.750626Z","shell.execute_reply.started":"2023-11-15T00:38:08.750456Z","shell.execute_reply":"2023-11-15T00:38:08.750473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from collections import OrderedDict\n# new_state_dict = OrderedDict()\n# for k, v in checkpoint['model'].items():\n#     name = k[7:] # remove `module.`\n#     new_state_dict[name] = v\n# # load params\n# model.load_state_dict(new_state_dict)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.751747Z","iopub.status.idle":"2023-11-15T00:38:08.752087Z","shell.execute_reply.started":"2023-11-15T00:38:08.751927Z","shell.execute_reply":"2023-11-15T00:38:08.751942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualize results**","metadata":{}},{"cell_type":"code","source":"# for i, (data, label) in enumerate(train_dataloader):\n#     img = data\n#     mask = label\n#     break","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.753560Z","iopub.status.idle":"2023-11-15T00:38:08.753935Z","shell.execute_reply.started":"2023-11-15T00:38:08.753725Z","shell.execute_reply":"2023-11-15T00:38:08.753748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig, arr = plt.subplots(4, 3, figsize=(16, 12))\n# arr[0][0].set_title('Image')\n# arr[0][1].set_title('Segmentation')\n# arr[0][2].set_title('Predict')\n\n# model.eval()\n# with torch.no_grad():\n#     predict = model(img)\n\n# for i in range(4):\n#     arr[i][0].imshow(img[i].permute(1, 2, 0));\n    \n#     arr[i][1].imshow(F.one_hot(mask[i]).float())\n    \n#     arr[i][2].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.755463Z","iopub.status.idle":"2023-11-15T00:38:08.755796Z","shell.execute_reply.started":"2023-11-15T00:38:08.755636Z","shell.execute_reply":"2023-11-15T00:38:08.755652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create submission**","metadata":{}},{"cell_type":"code","source":"transform = Compose([Resize((800, 1120), interpolation=InterpolationMode.BILINEAR),\n                     PILToTensor()])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.757465Z","iopub.status.idle":"2023-11-15T00:38:08.757793Z","shell.execute_reply.started":"2023-11-15T00:38:08.757635Z","shell.execute_reply":"2023-11-15T00:38:08.757650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNetTestDataClass(Dataset):\n    def __init__(self, images_path, transform):\n        super(UNetTestDataClass, self).__init__()\n        \n        images_list = os.listdir(images_path)\n        images_list = [images_path+i for i in images_list]\n        \n        self.images_list = images_list\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img_path = self.images_list[index]\n        data = Image.open(img_path)\n        h = data.size[1]\n        w = data.size[0]\n        data = self.transform(data) / 255        \n        return data, img_path, h, w\n    \n    def __len__(self):\n        return len(self.images_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.759136Z","iopub.status.idle":"2023-11-15T00:38:08.759479Z","shell.execute_reply.started":"2023-11-15T00:38:08.759308Z","shell.execute_reply":"2023-11-15T00:38:08.759324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/bkai-igh-neopolyp/test/test/'\nunet_test_dataset = UNetTestDataClass(path, transform)\ntest_dataloader = DataLoader(unet_test_dataset, batch_size=8, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.760740Z","iopub.status.idle":"2023-11-15T00:38:08.761079Z","shell.execute_reply.started":"2023-11-15T00:38:08.760920Z","shell.execute_reply":"2023-11-15T00:38:08.760936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, (data, path, h, w) in enumerate(test_dataloader):\n    img = data\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.762703Z","iopub.status.idle":"2023-11-15T00:38:08.763033Z","shell.execute_reply.started":"2023-11-15T00:38:08.762854Z","shell.execute_reply":"2023-11-15T00:38:08.762882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, arr = plt.subplots(5, 2, figsize=(16, 12))\narr[0][0].set_title('Image');\narr[0][1].set_title('Predict');\n\nmodel.eval()\nwith torch.no_grad():\n    predict = model(img)\n\nfor i in range(5):\n    arr[i][0].imshow(img[i].permute(1, 2, 0));\n    arr[i][1].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.763887Z","iopub.status.idle":"2023-11-15T00:38:08.764296Z","shell.execute_reply.started":"2023-11-15T00:38:08.764078Z","shell.execute_reply":"2023-11-15T00:38:08.764100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nif not os.path.isdir(\"/kaggle/working/predicted_masks\"):\n    os.mkdir(\"/kaggle/working/predicted_masks\")\nfor _, (img, path, H, W) in enumerate(test_dataloader):\n    a = path\n    b = img\n    h = H\n    w = W\n    \n    with torch.no_grad():\n        predicted_mask = model(b)\n    for i in range(len(a)):\n        image_id = a[i].split('/')[-1].split('.')[0]\n        filename = image_id + \".png\"\n        mask2img = Resize((h[i].item(), w[i].item()), interpolation=InterpolationMode.NEAREST)(ToPILImage()(F.one_hot(torch.argmax(predicted_mask[i], 0)).permute(2, 0, 1).float()))\n        mask2img.save(os.path.join(\"/kaggle/working/predicted_masks/\", filename))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.765757Z","iopub.status.idle":"2023-11-15T00:38:08.766094Z","shell.execute_reply.started":"2023-11-15T00:38:08.765936Z","shell.execute_reply":"2023-11-15T00:38:08.765951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 0] = 255\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    \n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return rle_to_string(rle)\n\ndef mask2string(dir):\n    ## mask --> string\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/predicted_masks' # change this to the path to your output mask folder\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\ndf.to_csv(r'output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T00:38:08.767459Z","iopub.status.idle":"2023-11-15T00:38:08.767772Z","shell.execute_reply.started":"2023-11-15T00:38:08.767616Z","shell.execute_reply":"2023-11-15T00:38:08.767631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}